{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59afc6a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. 加载数据集 ---\n",
      "数据集加载成功！\n",
      "documents.csv 包含 2004 条记录。\n",
      "annotations.csv 包含 41410 条记录。\n",
      "\n",
      "--- 2. 初步查看 documents.csv 的前几行 ---\n",
      "   id subcorpus native language_background level  words  sentences\n",
      "0   1     RULEC    eng                  HL    AM    431         22\n",
      "1   3     RULEC    eng                  HL    AM    245         17\n",
      "2   5     RULEC    eng                  FL    AM    472         22\n",
      "3   6     RULEC    eng                  FL    IH    319         24\n",
      "4   7     RULEC    eng                  HL    AL     44          2\n",
      "\n",
      "--- 2. 初步查看 annotations.csv 的前几行 ---\n",
      "       id  sentence_id              tag               quote  \\\n",
      "0    7944         1002            ortho           окружющей   \n",
      "1  101216         1006          agrcase        промышленным   \n",
      "2   18818         1009           syntax         воздействую   \n",
      "3  119778         1009     ortho,altern  желудожно-кишечный   \n",
      "4   18819         1012  syntax,transfer                 это   \n",
      "\n",
      "           correction  start  end annotation_source  \n",
      "0          окружающей     12   13            manual  \n",
      "1        промышленных      4    5            manual  \n",
      "2         воздействуя     12   13            manual  \n",
      "3  желудочно-кишечный     17   18            manual  \n",
      "4                          7    8            manual  \n",
      "\n",
      "--- documents.csv 的列名 ---\n",
      "['id', 'subcorpus', 'native', 'language_background', 'level', 'words', 'sentences']\n",
      "\n",
      "--- annotations.csv 的列名 ---\n",
      "['id', 'sentence_id', 'tag', 'quote', 'correction', 'start', 'end', 'annotation_source']\n",
      "\n",
      "警告：在 documents.csv 中未找到列 'document_id'。请检查实际列名。\n",
      "警告：在 annotations.csv 中未找到列 'document_id'。请检查实际列名。\n",
      "\n",
      "--- 3. 筛选目标学习者数据 ---\n",
      "筛选出 760 条来自目标母语学习者的记录。\n",
      "目标学习者的母语分布：\n",
      "native\n",
      "eng    760\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'document_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'document_id'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 54\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28mprint\u001b[39m(target_learners_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnative\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue_counts())\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# 提取目标学习者的 document_id (或其他唯一标识符)\u001b[39;00m\n\u001b[0;32m---> 54\u001b[0m target_document_ids \u001b[38;5;241m=\u001b[39m target_learners_df[document_id_col_doc]\u001b[38;5;241m.\u001b[39munique()\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m提取出 \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(target_document_ids)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m 个目标学习者的唯一文档ID。\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# --- 4. 在 annotations 文件中定位动词体（Asp）错误 ---\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.12/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'document_id'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# --- 1. 加载数据集 ---\n",
    "print(\"--- 1. 加载数据集 ---\")\n",
    "try:\n",
    "    documents_df = pd.read_csv('/Users/aloez/Downloads/documents.csv')\n",
    "    annotations_df = pd.read_csv('/Users/aloez/Downloads/annotations.csv')\n",
    "    print(\"数据集加载成功！\")\n",
    "    print(f\"documents.csv 包含 {len(documents_df)} 条记录。\")\n",
    "    print(f\"annotations.csv 包含 {len(annotations_df)} 条记录。\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"错误：请确保 'documents.csv' 和 'annotations.csv' 文件在当前目录下或提供正确路径。\")\n",
    "    exit() # 如果文件未找到，程序退出\n",
    "\n",
    "# --- 2. 初步查看数据结构 ---\n",
    "print(\"\\n--- 2. 初步查看 documents.csv 的前几行 ---\")\n",
    "print(documents_df.head())\n",
    "print(\"\\n--- 2. 初步查看 annotations.csv 的前几行 ---\")\n",
    "print(annotations_df.head())\n",
    "\n",
    "# 检查列名，确认是否存在 'native' 和 'tag'\n",
    "print(\"\\n--- documents.csv 的列名 ---\")\n",
    "print(documents_df.columns.tolist())\n",
    "print(\"\\n--- annotations.csv 的列名 ---\")\n",
    "print(annotations_df.columns.tolist())\n",
    "\n",
    "# 请根据实际输出，确认 `document_id` 或 `text_id` 等用于关联两个表的公共ID字段\n",
    "# 通常会有一个唯一的ID来连接文档信息和其对应的错误标注\n",
    "# 假设是 'document_id'，如果不是，请根据实际列名修改\n",
    "document_id_col_doc = 'document_id' # 假设 documents.csv 中的文档ID列名\n",
    "document_id_col_anno = 'document_id' # 假设 annotations.csv 中的文档ID列名\n",
    "\n",
    "if document_id_col_doc not in documents_df.columns:\n",
    "    print(f\"\\n警告：在 documents.csv 中未找到列 '{document_id_col_doc}'。请检查实际列名。\")\n",
    "if document_id_col_anno not in annotations_df.columns:\n",
    "    print(f\"警告：在 annotations.csv 中未找到列 '{document_id_col_anno}'。请检查实际列名。\")\n",
    "\n",
    "\n",
    "# --- 3. 筛选目标学习者数据 ---\n",
    "print(\"\\n--- 3. 筛选目标学习者数据 ---\")\n",
    "\n",
    "# 筛选母语为汉语 ('zho') 和英语 ('eng') 的学习者\n",
    "# 论文中通常使用ISO 639-2/3 代码，'zho'代表Chinese，'eng'代表English。\n",
    "# 请注意：如果您的数据集中使用了不同的编码（例如 'Chinese', 'English'），请修改这里的列表。\n",
    "target_languages = ['zho', 'eng']\n",
    "target_learners_df = documents_df[documents_df['native'].isin(target_languages)]\n",
    "\n",
    "print(f\"筛选出 {len(target_learners_df)} 条来自目标母语学习者的记录。\")\n",
    "print(\"目标学习者的母语分布：\")\n",
    "print(target_learners_df['native'].value_counts())\n",
    "\n",
    "# 提取目标学习者的 document_id (或其他唯一标识符)\n",
    "target_document_ids = target_learners_df[document_id_col_doc].unique()\n",
    "print(f\"提取出 {len(target_document_ids)} 个目标学习者的唯一文档ID。\")\n",
    "\n",
    "\n",
    "# --- 4. 在 annotations 文件中定位动词体（Asp）错误 ---\n",
    "print(\"\\n--- 4. 在 annotations 文件中定位动词体（Asp）错误 ---\")\n",
    "\n",
    "# 查找所有 tag 字段为 'Asp' 的错误记录\n",
    "# 根据论文，'Asp' 是动词体的标签。\n",
    "# 如果初步检查中未出现，请务必在运行此代码后，手动检查 annotations.csv 的完整内容，\n",
    "# 或尝试搜索其他可能的动词体相关标签（如'Aspect', 'VerbAspect'等）。\n",
    "aspect_errors_df = annotations_df[annotations_df['tag'] == 'Asp'].copy() # 使用.copy()避免SettingWithCopyWarning\n",
    "\n",
    "print(f\"在 annotations.csv 中找到 {len(aspect_errors_df)} 条 'Asp' 错误记录。\")\n",
    "if len(aspect_errors_df) == 0:\n",
    "    print(\"警告：未找到任何 'Asp' 标签的错误。请再次确认 'annotations.csv' 中的 'tag' 列是否存在此标签，或是否存在其他表示动词体的标签。\")\n",
    "    print(\"annotations.csv 中 tag 列出现的前10个标签类型：\")\n",
    "    print(annotations_df['tag'].value_counts().head(10)) # 打印前10个最常见的tag，帮助您识别\n",
    "\n",
    "# --- 5. 关联目标学习者数据与动词体错误标注 ---\n",
    "print(\"\\n--- 5. 关联目标学习者数据与动词体错误标注 ---\")\n",
    "\n",
    "# 将 aspect_errors_df 进一步筛选，只保留属于目标学习者的错误\n",
    "target_aspect_errors_df = aspect_errors_df[\n",
    "    aspect_errors_df[document_id_col_anno].isin(target_document_ids)\n",
    "].copy() # 使用.copy()避免SettingWithCopyWarning\n",
    "\n",
    "print(f\"最终筛选出 {len(target_aspect_errors_df)} 条来自目标学习者的动词体（Asp）错误。\")\n",
    "\n",
    "if len(target_aspect_errors_df) > 0:\n",
    "    print(\"\\n来自目标学习者的动词体错误示例（前5条）：\")\n",
    "    print(target_aspect_errors_df.head())\n",
    "\n",
    "    # （可选）合并 learning_native 信息到错误记录中，方便后续分析\n",
    "    # 确保合并时使用的 document_id 是共通的\n",
    "    merged_errors_df = pd.merge(\n",
    "        target_aspect_errors_df,\n",
    "        target_learners_df[[document_id_col_doc, 'native']],\n",
    "        left_on=document_id_col_anno,\n",
    "        right_on=document_id_col_doc,\n",
    "        how='left'\n",
    "    )\n",
    "    # 删除重复的 document_id 列，如果它们名称不同的话\n",
    "    if document_id_col_doc != document_id_col_anno:\n",
    "        merged_errors_df = merged_errors_df.drop(columns=[document_id_col_doc])\n",
    "\n",
    "    print(\"\\n合并学习者母语信息后的动词体错误示例（前5条）：\")\n",
    "    print(merged_errors_df.head())\n",
    "\n",
    "    # 查看这些错误的母语分布\n",
    "    print(\"\\n目标学习者动词体错误的母语分布：\")\n",
    "    print(merged_errors_df['native'].value_counts())\n",
    "\n",
    "    # 现在 merged_errors_df 包含了您需要的所有信息，可以保存以便后续分析\n",
    "    merged_errors_df.to_csv('target_aspect_errors.csv', index=False, encoding='utf-8-sig')\n",
    "    print(\"\\n已将筛选出的目标动词体错误保存到 'target_aspect_errors.csv'。\")\n",
    "\n",
    "else:\n",
    "    print(\"\\n没有找到来自目标学习者的动词体（Asp）错误。请检查标签名称是否正确或数据集内容。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e8a345c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 2. 加载数据 ---\n",
      "成功加载 '/Users/aloez/Downloads/asp（动词体）.csv'，包含 1487 条Asp错误记录。\n",
      "成功加载 '/Users/aloez/Downloads/native.csv'，包含 1064 条文档记录。\n",
      "\n",
      "--- 4. 合并 Asp 错误与学习者母语信息 ---\n",
      "合并后的数据框包含 1487 条记录。\n",
      "合并后的数据框前几行示例（包含 native 列）：\n",
      "       id  sentence_id             tag                   quote  \\\n",
      "0    9933         7002       asp,morph                   Стоив   \n",
      "1    7468        13001      constr,asp              имеет силь   \n",
      "2    8329        14003             asp      будет рассказывать   \n",
      "3  124608        15001             asp                 положит   \n",
      "4    8897        23016  constr,lex,asp  приехали в такие места   \n",
      "\n",
      "                correction  start  end annotation_source native  \n",
      "0                    Строя      0    1            manual    NaN  \n",
      "1                 начинает      5    7            manual    NaN  \n",
      "2                расскажет      2    4            manual    NaN  \n",
      "3                   кладет      3    4            manual    NaN  \n",
      "4  побывали в таких местах     12   16            manual    NaN  \n",
      "警告：有 1482 条 Asp 错误记录在 documents.csv 中未能找到对应的母语信息。\n",
      "\n",
      "--- 5. 按母语筛选并分离数据 ---\n",
      "合并数据中母语分布：\n",
      "native\n",
      "chi    3\n",
      "eng    2\n",
      "Name: count, dtype: int64\n",
      "筛选出 3 条来自汉语学习者的 Asp 错误记录。\n",
      "筛选出 2 条来自英语学习者的 Asp 错误记录。\n",
      "\n",
      "--- 6. 保存分离后的数据 ---\n",
      "已将汉语学习者的 Asp 错误保存到 'chinese_asp_errors_with_native.csv'。\n",
      "已将英语学习者的 Asp 错误保存到 'english_asp_errors_with_native.csv'。\n",
      "\n",
      "数据已准备就绪，可以进行下一步的精细分类和定性分析了！\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# --- 1. 定义文件路径和关键列名 ---\n",
    "# 请根据您实际的文件名和列名进行修改\n",
    "all_asp_errors_file = '/Users/aloez/Downloads/asp（动词体）.csv'  # 假设您将所有Asp错误保存到这个文件\n",
    "documents_file = '/Users/aloez/Downloads/native.csv'          # 包含学习者母语信息的documents文件\n",
    "\n",
    "# 这两个文件都有一个名为 'id' 的列用于关联\n",
    "common_id_column_name = 'id'\n",
    "native_language_column_name = 'native' # documents.csv中指示母语的列名\n",
    "tag_column_name = 'tag' # Asp错误文件中的错误类型列名\n",
    "\n",
    "# --- 2. 加载数据 ---\n",
    "print(\"--- 2. 加载数据 ---\")\n",
    "try:\n",
    "    # 加载包含所有Asp错误的CSV\n",
    "    all_asp_errors_df = pd.read_csv(all_asp_errors_file)\n",
    "    print(f\"成功加载 '{all_asp_errors_file}'，包含 {len(all_asp_errors_df)} 条Asp错误记录。\")\n",
    "\n",
    "    # 加载包含学习者元数据的documents.csv\n",
    "    documents_df = pd.read_csv(documents_file)\n",
    "    print(f\"成功加载 '{documents_file}'，包含 {len(documents_df)} 条文档记录。\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"错误：文件未找到。请检查文件名和路径是否正确：{e}\")\n",
    "    exit() # 如果文件未找到，程序退出\n",
    "\n",
    "# --- 3. 检查关键列是否存在 ---\n",
    "if common_id_column_name not in all_asp_errors_df.columns:\n",
    "    print(f\"警告：'{all_asp_errors_file}' 中未找到关联列 '{common_id_column_name}'。当前列有: {all_asp_errors_df.columns.tolist()}\")\n",
    "    print(\"请根据实际列名修改 'common_id_column_name' 变量。\")\n",
    "    exit()\n",
    "\n",
    "if common_id_column_name not in documents_df.columns:\n",
    "    print(f\"警告：'{documents_file}' 中未找到关联列 '{common_id_column_name}'。当前列有: {documents_df.columns.tolist()}\")\n",
    "    print(\"请根据实际列名修改 'common_id_column_name' 变量。\")\n",
    "    exit()\n",
    "\n",
    "if native_language_column_name not in documents_df.columns:\n",
    "    print(f\"警告：'{documents_file}' 中未找到母语列 '{native_language_column_name}'。当前列有: {documents_df.columns.tolist()}\")\n",
    "    print(\"请根据实际列名修改 'native_language_column_name' 变量。\")\n",
    "    exit()\n",
    "\n",
    "# --- 4. 合并数据框 ---\n",
    "print(\"\\n--- 4. 合并 Asp 错误与学习者母语信息 ---\")\n",
    "# 只选择 documents_df 中我们需要的列 (ID 和 native) 来合并，避免不必要的列\n",
    "learner_native_info = documents_df[[common_id_column_name, native_language_column_name]].copy()\n",
    "\n",
    "# 执行合并操作\n",
    "# left_on 和 right_on 指定了两个数据框中用于合并的列\n",
    "merged_asp_errors_df = pd.merge(\n",
    "    all_asp_errors_df,\n",
    "    learner_native_info,\n",
    "    left_on=common_id_column_name,\n",
    "    right_on=common_id_column_name,\n",
    "    how='left' # 'left' 合并保留所有 Asp 错误，并添加匹配的母语信息\n",
    ")\n",
    "\n",
    "print(f\"合并后的数据框包含 {len(merged_asp_errors_df)} 条记录。\")\n",
    "print(\"合并后的数据框前几行示例（包含 native 列）：\")\n",
    "print(merged_asp_errors_df.head())\n",
    "\n",
    "# 检查合并后是否有缺失的 native 信息（可能意味着某些 document_id 在 documents.csv 中找不到）\n",
    "missing_native_count = merged_asp_errors_df[native_language_column_name].isnull().sum()\n",
    "if missing_native_count > 0:\n",
    "    print(f\"警告：有 {missing_native_count} 条 Asp 错误记录在 documents.csv 中未能找到对应的母语信息。\")\n",
    "\n",
    "# --- 5. 按母语筛选并分离数据 ---\n",
    "print(\"\\n--- 5. 按母语筛选并分离数据 ---\")\n",
    "\n",
    "# 确认母语编码，如 'chi' 和 'eng'\n",
    "# 您可以先查看 merged_asp_errors_df['native'].value_counts() 来确认实际的母语编码\n",
    "print(\"合并数据中母语分布：\")\n",
    "print(merged_asp_errors_df[native_language_column_name].value_counts())\n",
    "\n",
    "chinese_asp_errors_df = merged_asp_errors_df[merged_asp_errors_df[native_language_column_name] == 'chi'].copy()\n",
    "english_asp_errors_df = merged_asp_errors_df[merged_asp_errors_df[native_language_column_name] == 'eng'].copy()\n",
    "\n",
    "print(f\"筛选出 {len(chinese_asp_errors_df)} 条来自汉语学习者的 Asp 错误记录。\")\n",
    "print(f\"筛选出 {len(english_asp_errors_df)} 条来自英语学习者的 Asp 错误记录。\")\n",
    "\n",
    "# --- 6. 保存分离后的数据（可选，但推荐） ---\n",
    "print(\"\\n--- 6. 保存分离后的数据 ---\")\n",
    "chinese_asp_errors_df.to_csv('chinese_asp_errors_with_native.csv', index=False, encoding='utf-8-sig')\n",
    "english_asp_errors_df.to_csv('english_asp_errors_with_native.csv', index=False, encoding='utf-8-sig')\n",
    "print(\"已将汉语学习者的 Asp 错误保存到 'chinese_asp_errors_with_native.csv'。\")\n",
    "print(\"已将英语学习者的 Asp 错误保存到 'english_asp_errors_with_native.csv'。\")\n",
    "\n",
    "print(\"\\n数据已准备就绪，可以进行下一步的精细分类和定性分析了！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0dc80a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
